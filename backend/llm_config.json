{
    "TAGGING": {
        "model_name": "gemini-2.0-flash",
        "temperature": 0.0,
        "max_output_tokens": 8192,
        "top_p": 1.0,
        "top_k": 40
    },
    "ANALYSIS": {
        "model_name": "gemini-2.5-flash",
        "temperature": 0.0,
        "max_output_tokens": 65536,
        "top_p": 1.0,
        "top_k": 40,
        "thinking_config": null
    },
    "PROCESSING": {
        "API_TIMEOUT": 300,
        "EMBEDDING_MODEL": "text-embedding-004",
        "TERM_CLUSTERING_THRESHOLD": 0.60,
        "RULE_CLUSTERING_THRESHOLD": 0.60,
        "MAX_SECTION_CHARS": 5000,
        "EMBEDDING_BATCH_SIZE": 100
    },
    "HIPDAM": {
        "AGENTS": {
            "AGENT_1": {
                "name": "Obligation Extractor",
                "model": "gemini-2.5-flash",
                "temperature": 0.0,
                "top_p": 0.95,
                "prompt_file": "prompts/agent_1_prompt.txt"
            },
            "AGENT_2": {
                "name": "Risk Extractor",
                "model": "gemini-2.5-flash",
                "temperature": 0.2,
                "top_p": 0.95,
                "prompt_file": "prompts/agent_2_prompt.txt"
            },
            "AGENT_3": {
                "name": "Definition Extractor",
                "model": "gemini-2.5-flash",
                "temperature": 0.0,
                "top_p": 0.95,
                "prompt_file": "prompts/agent_3_prompt.txt"
            },
            "AGENT_4": {
                "name": "General Scout A",
                "model": "gemini-2.5-flash",
                "temperature": 0.7,
                "top_p": 0.95,
                "prompt_file": "prompts/agent_4_prompt.txt"
            },
            "AGENT_5": {
                "name": "General Scout B",
                "model": "gemini-2.5-flash",
                "temperature": 0.7,
                "top_p": 0.95,
                "prompt_file": "prompts/agent_5_prompt.txt"
            }
        },
        "JUDGE": {
            "model": "gemini-2.5-pro",
            "temperature": 0.0,
            "prompt_file": "prompts/judge_prompt.txt"
        },
        "CLUSTERING": {
            "threshold": 0.85,
            "model": "text-embedding-004"
        }
    },
    "REVIEW": {
        "model_name": "gemini-1.5-pro",
        "temperature": 0.1,
        "max_output_tokens": 8192,
        "top_p": 0.95,
        "top_k": 40
    },
    "DEFAULT": {
        "model_name": "gemini-2.0-flash",
        "temperature": 0.0,
        "max_output_tokens": 8192,
        "top_p": 0.95,
        "top_k": 40
    }
}